{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091c64dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style><style>.output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML('<style>.container { width:95% !important; }</style><style>.output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef41a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import io\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from random import shuffle\n",
    "import fitz\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25f530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_path=r'E:\\planning_validator_data\\raw_data\\sorted_doc_types\\image_based\\new_download-15-2-22\\for_labelling_azure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f88b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files=listdir('labels')\n",
    "def read_csv(file):\n",
    "    return pd.read_csv('labels\\\\'+file)\n",
    "labels=map(read_csv,label_files)\n",
    "labels=pd.concat(list(labels))\n",
    "labels=labels.dropna(subset=['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bb9e74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "targets = []\n",
    "min_instance_len_in_characters=1\n",
    "\n",
    "for idx, row in labels.iterrows():\n",
    "    for folder in listdir(documents_path):\n",
    "        for file in listdir(join(documents_path,folder)):\n",
    "            if isfile(join(documents_path,folder,file)):\n",
    "                if row[0] == file:\n",
    "                    if file.endswith('.pdf'):\n",
    "                        filename_path = join(documents_path,folder,file)\n",
    "                        doc=fitz.open(filename_path)\n",
    "                        token_text=''\n",
    "                        for page in doc:\n",
    "                            text = page.get_text('text').strip()\n",
    "                            token_text = token_text+text\n",
    "                            text=''\n",
    "                        if len(token_text)>min_instance_len_in_characters:\n",
    "                            documents.append(token_text)\n",
    "                            #print(folder,file)\n",
    "                            try:\n",
    "                                targets.append(ast.literal_eval(row[1]))\n",
    "                            except:\n",
    "                                print(folder,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54737ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize as normalize_func\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vectorizer import TfIdfVectorizer\n",
    "from vectorizer import CompositeTextVectorizer\n",
    "\n",
    "def training_pipeline(documents,targets,clf):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(targets)\n",
    "    y=mlb.transform(targets)\n",
    "\n",
    "    # split train test\n",
    "    documents_train, documents_valid, y_train, y_valid = train_test_split(documents, y, test_size=0.3, random_state=42)    \n",
    "    vectorizer=TfidfVectorizer(stop_words='english', analyzer='char_wb', ngram_range=(3,7)).fit(documents_train)\n",
    "    vectors=vectorizer.transform(documents_train)\n",
    "    svd=TruncatedSVD(n_components=200, random_state=42).fit(vectors)\n",
    "    truncated=svd.transform(vectors)\n",
    "    x_train=normalize_func(truncated)\n",
    "\n",
    "    model=clf.fit(x_train, y_train)\n",
    "\n",
    "    vectors_valid=vectorizer.transform(documents_valid)\n",
    "    trunc_valid=svd.transform(vectors_valid)\n",
    "    x_valid=normalize_func(trunc_valid)\n",
    "    preds=model.predict(x_valid)\n",
    "\n",
    "    score=model.score(x_valid,y_valid)\n",
    "    lrap_score=label_ranking_average_precision_score(y_valid, preds)\n",
    "\n",
    "    return model,mlb,vectorizer,svd,score,lrap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564ce0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rucha.dalwadi.AGILESAAS\\Anaconda3\\envs\\objdet-venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:538: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n",
      "C:\\Users\\rucha.dalwadi.AGILESAAS\\Anaconda3\\envs\\objdet-venv\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rucha.dalwadi.AGILESAAS\\Anaconda3\\envs\\objdet-venv\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rucha.dalwadi.AGILESAAS\\Anaconda3\\envs\\objdet-venv\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rucha.dalwadi.AGILESAAS\\Anaconda3\\envs\\objdet-venv\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rucha.dalwadi.AGILESAAS\\Anaconda3\\envs\\objdet-venv\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_svc_weighted = MultiOutputClassifier(OneVsRestClassifier(SVC(C=100, kernel='rbf', gamma='scale', probability=True, class_weight='balanced')))\n",
    "model_svc,mlb_svc,vectorizer_svc,svd_svc,score_svc,lrap_score_svc = training_pipeline(documents,targets,clf_svc_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3069cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1707 | Label ranking average precision score: 0.3669\n"
     ]
    }
   ],
   "source": [
    "print(f'Score: {score_svc:.4f} | Label ranking average precision score: {lrap_score_svc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objdet",
   "language": "python",
   "name": "objdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
